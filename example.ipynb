{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4b2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graph.example_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_graph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleGraph\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExampleState\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI, AzureChatOpenAI, AzureOpenAI\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'graph.example_graph'"
     ]
    }
   ],
   "source": [
    "from graph.example_graph import ExampleGraph\n",
    "from models.example_state import ExampleState\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI, AzureOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_ollama import ChatOllama\n",
    "import os\n",
    "from rich import print as pp\n",
    "\n",
    "# llm = AzureChatOpenAI(\n",
    "#     azure_deployment=\"gpt-4o\",\n",
    "#     openai_api_version=\"2025-01-01-preview\",         \n",
    "#     azure_endpoint=\"https://mech-llm-prod.openai.azure.com/\",  \n",
    "#     api_key=os.environ.get(\"OPENAI_KEY\"),                 \n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0.7          \n",
    "# )\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-preview-05-20\",\n",
    "        api_key=os.environ.get(\"GOOGLE_API_KEY\"),  # Your Google API key\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b5b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.example_validation import ExampleValidation\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "output=PydanticOutputParser(pydantic_object=ExampleValidation).get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de53ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Doc String\", \"properties\": {\"output\": {\"description\": \"Output Description\", \"title\": \"Output\", \"type\": \"string\"}, \"input\": {\"description\": \"Input Description\", \"title\": \"Input\", \"type\": \"string\"}, \"insights\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"Insights from the validation process\", \"title\": \"Insights\"}}, \"required\": [\"output\", \"input\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09022766",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = ExampleState(\n",
    "    equipment=\"Centrifugal Pump\",\n",
    "    component=\"Induction Motor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_graph = ExampleGraph(\n",
    "    state=ExampleState,\n",
    "    llm=llm,\n",
    "    logging=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b605c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = final_graph.invoke_graph(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2024fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prompt_management import PromptManager\n",
    "pm = PromptManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8670ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797f6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcd09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
